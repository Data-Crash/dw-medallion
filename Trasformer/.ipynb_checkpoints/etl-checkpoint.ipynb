{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8450e908",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "710952ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "import os\n",
    "\n",
    "\n",
    "POST_JDBC = \"/app/postgresql-42.7.8.jar\"\n",
    "FILE_TABELAS_DIR = \"/app/parquet_tables\"\n",
    "SCRATCH = \"/spark_temp\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215e8b4",
   "metadata": {},
   "source": [
    "### Spark Session Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051f1266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/11 11:34:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/10/11 11:34:41 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataCrash-ETL\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", POST_JDBC)\\\n",
    "    .config(\"spark.executor.extraClassPath\", POST_JDBC)\\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"CORRECTED\")\\\n",
    "    .config(\"spark.local.dir\", SCRATCH)\\\n",
    "    .config(\"spark.master\", \"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.worker.cleanup.enabled\", \"true\")\\\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db781c",
   "metadata": {},
   "source": [
    "### Column Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40bf7537",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column definitions loaded\n"
     ]
    }
   ],
   "source": [
    "def get_accident_columns():\n",
    "    \"\"\"Return list of columns to KEEP for accidents\"\"\"\n",
    "    return [\n",
    "        'Accident_Index', 'Longitude', 'Latitude', 'Accident_Severity',\n",
    "        'Number_of_Vehicles', 'Number_of_Casualties', 'Date', 'Day_of_Week', \n",
    "        'Time', 'Road_Type', 'Speed_limit', 'Junction_Detail', 'Junction_Control',\n",
    "        'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions', \n",
    "        'Weather_Conditions', 'Road_Surface_Conditions', 'Special_Conditions_at_Site',\n",
    "        'Carriageway_Hazards', 'Urban_or_Rural_Area'\n",
    "    ]\n",
    "\n",
    "def get_vehicle_columns():\n",
    "    \"\"\"Return list of columns to KEEP for vehicles\"\"\"\n",
    "    return [\n",
    "        'Accident_Index', 'Vehicle_Reference', 'Vehicle_Type',\n",
    "        'Vehicle_Manoeuvre', 'Vehicle_Location-Restricted_Lane',\n",
    "        'Was_Vehicle_Left_Hand_Drive?', 'Sex_of_Driver', 'Age_of_Driver',\n",
    "        'Age_Band_of_Driver', 'Propulsion_Code', 'Age_of_Vehicle'\n",
    "    ]\n",
    "\n",
    "def get_casualty_columns():\n",
    "    \"\"\"Return list of columns to KEEP for casualties\"\"\"\n",
    "    return [\n",
    "        'Accident_Index', 'Vehicle_Reference', 'Casualty_Reference',\n",
    "        'Casualty_Class', 'Sex_of_Casualty', 'Age_of_Casualty',\n",
    "        'Age_Band_of_Casualty', 'Casualty_Severity', 'Pedestrian_Movement',\n",
    "        'Car_Passenger', 'Bus_or_Coach_Passenger', 'Casualty_Type'\n",
    "    ]\n",
    "\n",
    "print(\"Column definitions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b7dff",
   "metadata": {},
   "source": [
    "### Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23690d96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_and_filter_data(file_path, columns_to_keep):\n",
    "\n",
    "\n",
    "    df_complete = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .parquet(file_path)\n",
    "\n",
    "    print(f\"{file_path}: {df_complete.count():,} rows, {len(df_complete.columns)} columns\")\n",
    "    df_complete.printSchema()\n",
    "\n",
    "    \n",
    "    existing_columns = [col for col in columns_to_keep if col in df_complete.columns]\n",
    "    df_filtered = df_complete.select(existing_columns)\n",
    "    \n",
    "    print(f\"Filtered: {len(df_filtered.columns)} columns kept\")\n",
    "    df_filtered.printSchema()\n",
    "    print(f\"Sample data from {file_path}:\")\n",
    "    df_filtered.show(5, truncate=False)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19399da",
   "metadata": {},
   "source": [
    "### Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76e5211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data_Layer/raw/parquet/Accidents0515: 1,780,653 rows, 32 columns\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Location_Easting_OSGR: integer (nullable = true)\n",
      " |-- Location_Northing_OSGR: integer (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Police_Force: integer (nullable = true)\n",
      " |-- Accident_Severity: integer (nullable = true)\n",
      " |-- Number_of_Vehicles: integer (nullable = true)\n",
      " |-- Number_of_Casualties: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Day_of_Week: integer (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Local_Authority_(District): integer (nullable = true)\n",
      " |-- Local_Authority_(Highway): string (nullable = true)\n",
      " |-- 1st_Road_Class: integer (nullable = true)\n",
      " |-- 1st_Road_Number: integer (nullable = true)\n",
      " |-- Road_Type: integer (nullable = true)\n",
      " |-- Speed_limit: integer (nullable = true)\n",
      " |-- Junction_Detail: integer (nullable = true)\n",
      " |-- Junction_Control: integer (nullable = true)\n",
      " |-- 2nd_Road_Class: integer (nullable = true)\n",
      " |-- 2nd_Road_Number: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Human_Control: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Physical_Facilities: integer (nullable = true)\n",
      " |-- Light_Conditions: integer (nullable = true)\n",
      " |-- Weather_Conditions: integer (nullable = true)\n",
      " |-- Road_Surface_Conditions: integer (nullable = true)\n",
      " |-- Special_Conditions_at_Site: integer (nullable = true)\n",
      " |-- Carriageway_Hazards: integer (nullable = true)\n",
      " |-- Urban_or_Rural_Area: integer (nullable = true)\n",
      " |-- Did_Police_Officer_Attend_Scene_of_Accident: integer (nullable = true)\n",
      " |-- LSOA_of_Accident_Location: string (nullable = true)\n",
      "\n",
      "Filtered: 20 columns kept\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Accident_Severity: integer (nullable = true)\n",
      " |-- Number_of_Vehicles: integer (nullable = true)\n",
      " |-- Number_of_Casualties: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Day_of_Week: integer (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Road_Type: integer (nullable = true)\n",
      " |-- Speed_limit: integer (nullable = true)\n",
      " |-- Junction_Detail: integer (nullable = true)\n",
      " |-- Junction_Control: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Physical_Facilities: integer (nullable = true)\n",
      " |-- Light_Conditions: integer (nullable = true)\n",
      " |-- Weather_Conditions: integer (nullable = true)\n",
      " |-- Road_Surface_Conditions: integer (nullable = true)\n",
      " |-- Special_Conditions_at_Site: integer (nullable = true)\n",
      " |-- Carriageway_Hazards: integer (nullable = true)\n",
      " |-- Urban_or_Rural_Area: integer (nullable = true)\n",
      "\n",
      "Sample data from ../Data_Layer/raw/parquet/Accidents0515:\n",
      "+--------------+---------+---------+-----------------+------------------+--------------------+----------+-----------+-------------------+---------+-----------+---------------+----------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+\n",
      "|Accident_Index|Longitude|Latitude |Accident_Severity|Number_of_Vehicles|Number_of_Casualties|Date      |Day_of_Week|Time               |Road_Type|Speed_limit|Junction_Detail|Junction_Control|Pedestrian_Crossing-Physical_Facilities|Light_Conditions|Weather_Conditions|Road_Surface_Conditions|Special_Conditions_at_Site|Carriageway_Hazards|Urban_or_Rural_Area|\n",
      "+--------------+---------+---------+-----------------+------------------+--------------------+----------+-----------+-------------------+---------+-----------+---------------+----------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+\n",
      "|201001CW11044 |-0.126838|51.49474 |3                |2                 |1                   |25/05/2010|3          |2025-10-31 09:20:00|6        |30         |6              |4               |0                                      |1               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11047 |-0.173004|51.521907|3                |2                 |1                   |04/06/2010|6          |2025-10-31 23:30:00|6        |30         |6              |2               |5                                      |4               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11048 |-0.177974|51.541858|3                |1                 |1                   |05/06/2010|7          |2025-10-31 11:35:00|6        |30         |0              |-1              |0                                      |1               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11049 |-0.128608|51.511315|3                |2                 |1                   |05/06/2010|7          |2025-10-31 21:12:00|6        |30         |3              |2               |5                                      |4               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11050 |-0.16238 |51.542334|3                |2                 |1                   |03/06/2010|5          |2025-10-31 09:10:00|6        |30         |3              |4               |0                                      |1               |1                 |1                      |0                         |0                  |1                  |\n",
      "+--------------+---------+---------+-----------------+------------------+--------------------+----------+-----------+-------------------+---------+-----------+---------------+----------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "../Data_Layer/raw/parquet/Vehicles0515: 3,262,270 rows, 22 columns\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Vehicle_Type: integer (nullable = true)\n",
      " |-- Towing_and_Articulation: integer (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: integer (nullable = true)\n",
      " |-- Vehicle_Location-Restricted_Lane: integer (nullable = true)\n",
      " |-- Junction_Location: integer (nullable = true)\n",
      " |-- Skidding_and_Overturning: integer (nullable = true)\n",
      " |-- Hit_Object_in_Carriageway: integer (nullable = true)\n",
      " |-- Vehicle_Leaving_Carriageway: integer (nullable = true)\n",
      " |-- Hit_Object_off_Carriageway: integer (nullable = true)\n",
      " |-- 1st_Point_of_Impact: integer (nullable = true)\n",
      " |-- Was_Vehicle_Left_Hand_Drive?: integer (nullable = true)\n",
      " |-- Journey_Purpose_of_Driver: integer (nullable = true)\n",
      " |-- Sex_of_Driver: integer (nullable = true)\n",
      " |-- Age_of_Driver: integer (nullable = true)\n",
      " |-- Age_Band_of_Driver: integer (nullable = true)\n",
      " |-- Engine_Capacity_(CC): integer (nullable = true)\n",
      " |-- Propulsion_Code: integer (nullable = true)\n",
      " |-- Age_of_Vehicle: integer (nullable = true)\n",
      " |-- Driver_IMD_Decile: integer (nullable = true)\n",
      " |-- Driver_Home_Area_Type: integer (nullable = true)\n",
      "\n",
      "Filtered: 11 columns kept\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Vehicle_Type: integer (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: integer (nullable = true)\n",
      " |-- Vehicle_Location-Restricted_Lane: integer (nullable = true)\n",
      " |-- Was_Vehicle_Left_Hand_Drive?: integer (nullable = true)\n",
      " |-- Sex_of_Driver: integer (nullable = true)\n",
      " |-- Age_of_Driver: integer (nullable = true)\n",
      " |-- Age_Band_of_Driver: integer (nullable = true)\n",
      " |-- Propulsion_Code: integer (nullable = true)\n",
      " |-- Age_of_Vehicle: integer (nullable = true)\n",
      "\n",
      "Sample data from ../Data_Layer/raw/parquet/Vehicles0515:\n",
      "+--------------+-----------------+------------+-----------------+--------------------------------+----------------------------+-------------+-------------+------------------+---------------+--------------+\n",
      "|Accident_Index|Vehicle_Reference|Vehicle_Type|Vehicle_Manoeuvre|Vehicle_Location-Restricted_Lane|Was_Vehicle_Left_Hand_Drive?|Sex_of_Driver|Age_of_Driver|Age_Band_of_Driver|Propulsion_Code|Age_of_Vehicle|\n",
      "+--------------+-----------------+------------+-----------------+--------------------------------+----------------------------+-------------+-------------+------------------+---------------+--------------+\n",
      "|201001CW12071 |2                |1           |14               |0                               |1                           |1            |27           |6                 |-1             |-1            |\n",
      "|201001CW12072 |1                |9           |18               |0                               |1                           |1            |55           |8                 |2              |7             |\n",
      "|201001CW12072 |2                |90          |18               |0                               |1                           |1            |35           |6                 |2              |6             |\n",
      "|201001CW12073 |1                |11          |13               |0                               |1                           |1            |-1           |-1                |2              |6             |\n",
      "|201001CW12073 |2                |1           |18               |0                               |1                           |2            |27           |6                 |-1             |-1            |\n",
      "+--------------+-----------------+------------+-----------------+--------------------------------+----------------------------+-------------+-------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "../Data_Layer/raw/parquet/Casualties0515: 2,402,909 rows, 15 columns\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Casualty_Reference: integer (nullable = true)\n",
      " |-- Casualty_Class: integer (nullable = true)\n",
      " |-- Sex_of_Casualty: integer (nullable = true)\n",
      " |-- Age_of_Casualty: integer (nullable = true)\n",
      " |-- Age_Band_of_Casualty: integer (nullable = true)\n",
      " |-- Casualty_Severity: integer (nullable = true)\n",
      " |-- Pedestrian_Location: integer (nullable = true)\n",
      " |-- Pedestrian_Movement: integer (nullable = true)\n",
      " |-- Car_Passenger: integer (nullable = true)\n",
      " |-- Bus_or_Coach_Passenger: integer (nullable = true)\n",
      " |-- Pedestrian_Road_Maintenance_Worker: integer (nullable = true)\n",
      " |-- Casualty_Type: integer (nullable = true)\n",
      " |-- Casualty_Home_Area_Type: integer (nullable = true)\n",
      "\n",
      "Filtered: 12 columns kept\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Casualty_Reference: integer (nullable = true)\n",
      " |-- Casualty_Class: integer (nullable = true)\n",
      " |-- Sex_of_Casualty: integer (nullable = true)\n",
      " |-- Age_of_Casualty: integer (nullable = true)\n",
      " |-- Age_Band_of_Casualty: integer (nullable = true)\n",
      " |-- Casualty_Severity: integer (nullable = true)\n",
      " |-- Pedestrian_Movement: integer (nullable = true)\n",
      " |-- Car_Passenger: integer (nullable = true)\n",
      " |-- Bus_or_Coach_Passenger: integer (nullable = true)\n",
      " |-- Casualty_Type: integer (nullable = true)\n",
      "\n",
      "Sample data from ../Data_Layer/raw/parquet/Casualties0515:\n",
      "+--------------+-----------------+------------------+--------------+---------------+---------------+--------------------+-----------------+-------------------+-------------+----------------------+-------------+\n",
      "|Accident_Index|Vehicle_Reference|Casualty_Reference|Casualty_Class|Sex_of_Casualty|Age_of_Casualty|Age_Band_of_Casualty|Casualty_Severity|Pedestrian_Movement|Car_Passenger|Bus_or_Coach_Passenger|Casualty_Type|\n",
      "+--------------+-----------------+------------------+--------------+---------------+---------------+--------------------+-----------------+-------------------+-------------+----------------------+-------------+\n",
      "|201001LX50242 |1                |1                 |1             |1              |44             |7                   |3                |0                  |0            |0                     |9            |\n",
      "|201001LX50242 |1                |2                 |2             |1              |10             |2                   |3                |0                  |2            |0                     |9            |\n",
      "|201001LX50244 |2                |1                 |1             |1              |21             |5                   |3                |0                  |0            |0                     |1            |\n",
      "|201001LX50245 |1                |1                 |1             |1              |31             |6                   |3                |0                  |0            |0                     |2            |\n",
      "|201001LX50246 |2                |1                 |1             |1              |59             |9                   |2                |0                  |0            |0                     |1            |\n",
      "+--------------+-----------------+------------------+--------------+---------------+---------------+--------------------+-----------------+-------------------+-------------+----------------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------+-----------------+------------------+--------------------+----------+-----------+-------------------+---------+-----------+---------------+----------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+\n",
      "|Accident_Index|Longitude|Latitude |Accident_Severity|Number_of_Vehicles|Number_of_Casualties|Date      |Day_of_Week|Time               |Road_Type|Speed_limit|Junction_Detail|Junction_Control|Pedestrian_Crossing-Physical_Facilities|Light_Conditions|Weather_Conditions|Road_Surface_Conditions|Special_Conditions_at_Site|Carriageway_Hazards|Urban_or_Rural_Area|\n",
      "+--------------+---------+---------+-----------------+------------------+--------------------+----------+-----------+-------------------+---------+-----------+---------------+----------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+\n",
      "|201001CW11044 |-0.126838|51.49474 |3                |2                 |1                   |25/05/2010|3          |2025-10-11 09:20:00|6        |30         |6              |4               |0                                      |1               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11047 |-0.173004|51.521907|3                |2                 |1                   |04/06/2010|6          |2025-10-11 23:30:00|6        |30         |6              |2               |5                                      |4               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11048 |-0.177974|51.541858|3                |1                 |1                   |05/06/2010|7          |2025-10-11 11:35:00|6        |30         |0              |-1              |0                                      |1               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11049 |-0.128608|51.511315|3                |2                 |1                   |05/06/2010|7          |2025-10-11 21:12:00|6        |30         |3              |2               |5                                      |4               |1                 |1                      |0                         |0                  |1                  |\n",
      "|201001CW11050 |-0.16238 |51.542334|3                |2                 |1                   |03/06/2010|5          |2025-10-11 09:10:00|6        |30         |3              |4               |0                                      |1               |1                 |1                      |0                         |0                  |1                  |\n",
      "+--------------+---------+---------+-----------------+------------------+--------------------+----------+-----------+-------------------+---------+-----------+---------------+----------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raw/Vehicles0515: 3,262,270 rows, 22 columns\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Vehicle_Type: integer (nullable = true)\n",
      " |-- Towing_and_Articulation: integer (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: integer (nullable = true)\n",
      " |-- Vehicle_Location-Restricted_Lane: integer (nullable = true)\n",
      " |-- Junction_Location: integer (nullable = true)\n",
      " |-- Skidding_and_Overturning: integer (nullable = true)\n",
      " |-- Hit_Object_in_Carriageway: integer (nullable = true)\n",
      " |-- Vehicle_Leaving_Carriageway: integer (nullable = true)\n",
      " |-- Hit_Object_off_Carriageway: integer (nullable = true)\n",
      " |-- 1st_Point_of_Impact: integer (nullable = true)\n",
      " |-- Was_Vehicle_Left_Hand_Drive?: integer (nullable = true)\n",
      " |-- Journey_Purpose_of_Driver: integer (nullable = true)\n",
      " |-- Sex_of_Driver: integer (nullable = true)\n",
      " |-- Age_of_Driver: integer (nullable = true)\n",
      " |-- Age_Band_of_Driver: integer (nullable = true)\n",
      " |-- Engine_Capacity_(CC): integer (nullable = true)\n",
      " |-- Propulsion_Code: integer (nullable = true)\n",
      " |-- Age_of_Vehicle: integer (nullable = true)\n",
      " |-- Driver_IMD_Decile: integer (nullable = true)\n",
      " |-- Driver_Home_Area_Type: integer (nullable = true)\n",
      "\n",
      "Filtered: 11 columns kept\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Vehicle_Type: integer (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: integer (nullable = true)\n",
      " |-- Vehicle_Location-Restricted_Lane: integer (nullable = true)\n",
      " |-- Was_Vehicle_Left_Hand_Drive?: integer (nullable = true)\n",
      " |-- Sex_of_Driver: integer (nullable = true)\n",
      " |-- Age_of_Driver: integer (nullable = true)\n",
      " |-- Age_Band_of_Driver: integer (nullable = true)\n",
      " |-- Propulsion_Code: integer (nullable = true)\n",
      " |-- Age_of_Vehicle: integer (nullable = true)\n",
      "\n",
      "Sample data from /raw/Vehicles0515:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+------------+-----------------+--------------------------------+----------------------------+-------------+-------------+------------------+---------------+--------------+\n",
      "|Accident_Index|Vehicle_Reference|Vehicle_Type|Vehicle_Manoeuvre|Vehicle_Location-Restricted_Lane|Was_Vehicle_Left_Hand_Drive?|Sex_of_Driver|Age_of_Driver|Age_Band_of_Driver|Propulsion_Code|Age_of_Vehicle|\n",
      "+--------------+-----------------+------------+-----------------+--------------------------------+----------------------------+-------------+-------------+------------------+---------------+--------------+\n",
      "|201001CW12071 |2                |1           |14               |0                               |1                           |1            |27           |6                 |-1             |-1            |\n",
      "|201001CW12072 |1                |9           |18               |0                               |1                           |1            |55           |8                 |2              |7             |\n",
      "|201001CW12072 |2                |90          |18               |0                               |1                           |1            |35           |6                 |2              |6             |\n",
      "|201001CW12073 |1                |11          |13               |0                               |1                           |1            |-1           |-1                |2              |6             |\n",
      "|201001CW12073 |2                |1           |18               |0                               |1                           |2            |27           |6                 |-1             |-1            |\n",
      "+--------------+-----------------+------------+-----------------+--------------------------------+----------------------------+-------------+-------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raw/Casualties0515: 2,402,909 rows, 15 columns\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Casualty_Reference: integer (nullable = true)\n",
      " |-- Casualty_Class: integer (nullable = true)\n",
      " |-- Sex_of_Casualty: integer (nullable = true)\n",
      " |-- Age_of_Casualty: integer (nullable = true)\n",
      " |-- Age_Band_of_Casualty: integer (nullable = true)\n",
      " |-- Casualty_Severity: integer (nullable = true)\n",
      " |-- Pedestrian_Location: integer (nullable = true)\n",
      " |-- Pedestrian_Movement: integer (nullable = true)\n",
      " |-- Car_Passenger: integer (nullable = true)\n",
      " |-- Bus_or_Coach_Passenger: integer (nullable = true)\n",
      " |-- Pedestrian_Road_Maintenance_Worker: integer (nullable = true)\n",
      " |-- Casualty_Type: integer (nullable = true)\n",
      " |-- Casualty_Home_Area_Type: integer (nullable = true)\n",
      "\n",
      "Filtered: 12 columns kept\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Casualty_Reference: integer (nullable = true)\n",
      " |-- Casualty_Class: integer (nullable = true)\n",
      " |-- Sex_of_Casualty: integer (nullable = true)\n",
      " |-- Age_of_Casualty: integer (nullable = true)\n",
      " |-- Age_Band_of_Casualty: integer (nullable = true)\n",
      " |-- Casualty_Severity: integer (nullable = true)\n",
      " |-- Pedestrian_Movement: integer (nullable = true)\n",
      " |-- Car_Passenger: integer (nullable = true)\n",
      " |-- Bus_or_Coach_Passenger: integer (nullable = true)\n",
      " |-- Casualty_Type: integer (nullable = true)\n",
      "\n",
      "Sample data from /raw/Casualties0515:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+------------------+--------------+---------------+---------------+--------------------+-----------------+-------------------+-------------+----------------------+-------------+\n",
      "|Accident_Index|Vehicle_Reference|Casualty_Reference|Casualty_Class|Sex_of_Casualty|Age_of_Casualty|Age_Band_of_Casualty|Casualty_Severity|Pedestrian_Movement|Car_Passenger|Bus_or_Coach_Passenger|Casualty_Type|\n",
      "+--------------+-----------------+------------------+--------------+---------------+---------------+--------------------+-----------------+-------------------+-------------+----------------------+-------------+\n",
      "|201001LX50242 |1                |1                 |1             |1              |44             |7                   |3                |0                  |0            |0                     |9            |\n",
      "|201001LX50242 |1                |2                 |2             |1              |10             |2                   |3                |0                  |2            |0                     |9            |\n",
      "|201001LX50244 |2                |1                 |1             |1              |21             |5                   |3                |0                  |0            |0                     |1            |\n",
      "|201001LX50245 |1                |1                 |1             |1              |31             |6                   |3                |0                  |0            |0                     |2            |\n",
      "|201001LX50246 |2                |1                 |1             |1              |59             |9                   |2                |0                  |0            |0                     |1            |\n",
      "+--------------+-----------------+------------------+--------------+---------------+---------------+--------------------+-----------------+-------------------+-------------+----------------------+-------------+\n",
      "only showing top 5 rows\n",
      "‚úÖ All datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "df_accidents = load_and_filter_data(\n",
    "    \"../Data_Layer/raw/parquet/Accidents0515\",\n",
    "    get_accident_columns()\n",
    ")\n",
    "\n",
    "df_vehicles = load_and_filter_data(\n",
    "    \"../Data_Layer/raw/parquet/Vehicles0515\", \n",
    "    get_vehicle_columns()\n",
    ")\n",
    "\n",
    "df_casualties = load_and_filter_data(\n",
    "    \"../Data_Layer/raw/parquet/Casualties0515\",\n",
    "    get_casualty_columns()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f4aab",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7c2ee8-cb5a-4db0-bff3-15a7a8c455fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISANDO ACCIDENTS...\n",
      "\n",
      "Accidents - QUALITY ANALYSIS\n",
      "========================================\n",
      "Total rows: 1,780,653\n",
      "Total columns: 20\n",
      "\n",
      "Accident_Index:\n",
      "   NULL: 0\n",
      "   Type: StringType()\n",
      "   Samples: ['201001CW11044', '201001CW11047']\n",
      "\n",
      "Longitude:\n",
      "   NULL: 138\n",
      "   Type: DoubleType()\n",
      "   Samples: ['-0.126838', '-0.173004']\n",
      "\n",
      "Latitude:\n",
      "   NULL: 138\n",
      "   Type: DoubleType()\n",
      "   Samples: ['51.49474', '51.521907']\n",
      "\n",
      "Accident_Severity:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['3', '3']\n",
      "\n",
      "Number_of_Vehicles:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['2', '2']\n",
      "\n",
      "Number_of_Casualties:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Date:\n",
      "   NULL: 0\n",
      "   Type: StringType()\n",
      "   Samples: ['25/05/2010', '04/06/2010']\n",
      "\n",
      "Day_of_Week:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['3', '6']\n",
      "\n",
      "Time:\n",
      "   NULL: 151\n",
      "   Type: TimestampType()\n",
      "   Samples: ['2025-10-31 09:20:00', '2025-10-31 23:30:00']\n",
      "\n",
      "Road_Type:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['6', '6']\n",
      "\n",
      "Speed_limit:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['30', '30']\n",
      "\n",
      "Junction_Detail:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['6', '6']\n",
      "\n",
      "Junction_Control:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['4', '2']\n",
      "\n",
      "Pedestrian_Crossing-Physical_Facilities:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '5']\n",
      "\n",
      "Light_Conditions:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '4']\n",
      "\n",
      "Weather_Conditions:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Road_Surface_Conditions:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Special_Conditions_at_Site:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '0']\n",
      "\n",
      "Carriageway_Hazards:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '0']\n",
      "\n",
      "Urban_or_Rural_Area:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "RESUMO:\n",
      "--------------------\n",
      "Problemas encontrados: 3\n",
      "   ‚Ä¢ Longitude: 138 NULL\n",
      "   ‚Ä¢ Latitude: 138 NULL\n",
      "   ‚Ä¢ Time: 151 NULL\n",
      "\n",
      "ANALISANDO VEHICLES...\n",
      "\n",
      "Vehicles - QUALITY ANALYSIS\n",
      "========================================\n",
      "Total rows: 3,262,270\n",
      "Total columns: 11\n",
      "\n",
      "Accident_Index:\n",
      "   NULL: 0\n",
      "   Type: StringType()\n",
      "   Samples: ['201001CW12071', '201001CW12072']\n",
      "\n",
      "Vehicle_Reference:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['2', '1']\n",
      "\n",
      "Vehicle_Type:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '9']\n",
      "\n",
      "Vehicle_Manoeuvre:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['14', '18']\n",
      "\n",
      "Vehicle_Location-Restricted_Lane:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '0']\n",
      "\n",
      "Was_Vehicle_Left_Hand_Drive?:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Sex_of_Driver:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Age_of_Driver:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['27', '55']\n",
      "\n",
      "Age_Band_of_Driver:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['6', '8']\n",
      "\n",
      "Propulsion_Code:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['-1', '2']\n",
      "\n",
      "Age_of_Vehicle:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['-1', '7']\n",
      "\n",
      "RESUMO:\n",
      "--------------------\n",
      "Nenhum problema encontrado!\n",
      "\n",
      "ANALISANDO CASUALTIES...\n",
      "\n",
      "Casualties - QUALITY ANALYSIS\n",
      "========================================\n",
      "Total rows: 2,402,909\n",
      "Total columns: 12\n",
      "\n",
      "Accident_Index:\n",
      "   NULL: 0\n",
      "   Type: StringType()\n",
      "   Samples: ['201001LX50242', '201001LX50242']\n",
      "\n",
      "Vehicle_Reference:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Casualty_Reference:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '2']\n",
      "\n",
      "Casualty_Class:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '2']\n",
      "\n",
      "Sex_of_Casualty:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['1', '1']\n",
      "\n",
      "Age_of_Casualty:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['44', '10']\n",
      "\n",
      "Age_Band_of_Casualty:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['7', '2']\n",
      "\n",
      "Casualty_Severity:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['3', '3']\n",
      "\n",
      "Pedestrian_Movement:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '0']\n",
      "\n",
      "Car_Passenger:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '2']\n",
      "\n",
      "Bus_or_Coach_Passenger:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['0', '0']\n",
      "\n",
      "Casualty_Type:\n",
      "   NULL: 0\n",
      "   Type: IntegerType()\n",
      "   Samples: ['9', '9']\n",
      "\n",
      "RESUMO:\n",
      "--------------------\n",
      "Nenhum problema encontrado!\n",
      "\n",
      "AN√ÅLISE DE QUALIDADE CONCLU√çDA PARA TODOS OS DATASETS!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: StringType()\n",
      "   üìã Samples: ['201001CW11044', '201001CW11047']\n",
      "\n",
      "Longitude:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ö†Ô∏è  NULL: 138\n",
      "   üè∑Ô∏è  Type: DoubleType()\n",
      "   üìã Samples: ['-0.126838', '-0.173004']\n",
      "\n",
      "Latitude:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ö†Ô∏è  NULL: 138\n",
      "   üè∑Ô∏è  Type: DoubleType()\n",
      "   üìã Samples: ['51.49474', '51.521907']\n",
      "\n",
      "Accident_Severity:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['3', '3']\n",
      "\n",
      "Number_of_Vehicles:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['2', '2']\n",
      "\n",
      "Number_of_Casualties:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Date:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: StringType()\n",
      "   üìã Samples: ['25/05/2010', '04/06/2010']\n",
      "\n",
      "Day_of_Week:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['3', '6']\n",
      "\n",
      "Time:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ö†Ô∏è  NULL: 151\n",
      "   üè∑Ô∏è  Type: TimestampType()\n",
      "   üìã Samples: ['2025-10-11 09:20:00', '2025-10-11 23:30:00']\n",
      "\n",
      "Road_Type:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['6', '6']\n",
      "\n",
      "Speed_limit:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['30', '30']\n",
      "\n",
      "Junction_Detail:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['6', '6']\n",
      "\n",
      "Junction_Control:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['4', '2']\n",
      "\n",
      "Pedestrian_Crossing-Physical_Facilities:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['0', '5']\n",
      "\n",
      "Light_Conditions:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '4']\n",
      "\n",
      "Weather_Conditions:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Road_Surface_Conditions:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Special_Conditions_at_Site:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['0', '0']\n",
      "\n",
      "Carriageway_Hazards:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['0', '0']\n",
      "\n",
      "Urban_or_Rural_Area:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "üìä RESUMO:\n",
      "--------------------\n",
      "‚ö†Ô∏è  Problemas encontrados: 3\n",
      "   ‚Ä¢ Longitude: 138 NULL\n",
      "   ‚Ä¢ Latitude: 138 NULL\n",
      "   ‚Ä¢ Time: 151 NULL\n",
      "\n",
      "ANALISANDO VEHICLES...\n",
      "\n",
      "üìä Vehicles - QUALITY ANALYSIS\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 3,262,270\n",
      "Total columns: 11\n",
      "\n",
      "Accident_Index:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: StringType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['201001CW12071', '201001CW12072']\n",
      "\n",
      "Vehicle_Reference:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['2', '1']\n",
      "\n",
      "Vehicle_Type:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['1', '9']\n",
      "\n",
      "Vehicle_Manoeuvre:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['14', '18']\n",
      "\n",
      "Vehicle_Location-Restricted_Lane:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['0', '0']\n",
      "\n",
      "Was_Vehicle_Left_Hand_Drive?:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Sex_of_Driver:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Age_of_Driver:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['27', '55']\n",
      "\n",
      "Age_Band_of_Driver:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['6', '8']\n",
      "\n",
      "Propulsion_Code:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['-1', '2']\n",
      "\n",
      "Age_of_Vehicle:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['-1', '7']\n",
      "\n",
      "üìä RESUMO:\n",
      "--------------------\n",
      "üéâ Nenhum problema encontrado!\n",
      "\n",
      "ANALISANDO CASUALTIES...\n",
      "\n",
      "üìä Casualties - QUALITY ANALYSIS\n",
      "========================================\n",
      "Total rows: 2,402,909\n",
      "Total columns: 12\n",
      "\n",
      "Accident_Index:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: StringType()\n",
      "   üìã Samples: ['201001LX50242', '201001LX50242']\n",
      "\n",
      "Vehicle_Reference:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Casualty_Reference:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n",
      "   üìã Samples: ['1', '2']\n",
      "\n",
      "Casualty_Class:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['1', '2']\n",
      "\n",
      "Sex_of_Casualty:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['1', '1']\n",
      "\n",
      "Age_of_Casualty:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['44', '10']\n",
      "\n",
      "Age_Band_of_Casualty:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['7', '2']\n",
      "\n",
      "Casualty_Severity:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['3', '3']\n",
      "\n",
      "Pedestrian_Movement:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['0', '0']\n",
      "\n",
      "Car_Passenger:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['0', '2']\n",
      "\n",
      "Bus_or_Coach_Passenger:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['0', '0']\n",
      "\n",
      "Casualty_Type:\n",
      "   ‚úÖ NULL: 0\n",
      "   üè∑Ô∏è  Type: IntegerType()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìã Samples: ['9', '9']\n",
      "\n",
      "üìä RESUMO:\n",
      "--------------------\n",
      "üéâ Nenhum problema encontrado!\n",
      "\n",
      "‚úÖ AN√ÅLISE DE QUALIDADE CONCLU√çDA PARA TODOS OS DATASETS!\n"
     ]
    }
   ],
   "source": [
    "def safe_quality_analysis(df, df_name):\n",
    "    print(f\"\\n{df_name} - QUALITY ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Contagem b√°sica\n",
    "    total_rows = df.count()\n",
    "    print(f\"Total rows: {total_rows:,}\")\n",
    "    print(f\"Total columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Lista de problemas\n",
    "    problems = []\n",
    "    \n",
    "    # Verificar cada coluna\n",
    "    for col_name in df.columns:\n",
    "        print(f\"\\n{col_name}:\")\n",
    "        \n",
    "        try:\n",
    "            # NULL values\n",
    "            null_count = df.filter(F.col(col_name).isNull()).count()\n",
    "            if null_count > 0:\n",
    "                print(f\"   NULL: {null_count}\")\n",
    "                problems.append(f\"{col_name}: {null_count} NULL\")\n",
    "            else:\n",
    "                print(f\"   NULL: 0\")\n",
    "                \n",
    "            # Data type\n",
    "            dtype = df.schema[col_name].dataType\n",
    "            print(f\"   Type: {dtype}\")\n",
    "            \n",
    "            # Amostra\n",
    "            samples = df.select(col_name).limit(2).collect()\n",
    "            sample_values = [str(row[col_name]) for row in samples]\n",
    "            print(f\"   Samples: {sample_values}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Erro ao analisar: {e}\")\n",
    "            problems.append(f\"{col_name}: ERRO - {e}\")\n",
    "    \n",
    "\n",
    "    print(f\"\\nRESUMO:\")\n",
    "    print(\"-\" * 20)\n",
    "    if problems:\n",
    "        print(f\"Problemas encontrados: {len(problems)}\")\n",
    "        for problem in problems:\n",
    "            print(f\"   ‚Ä¢ {problem}\")\n",
    "    else:\n",
    "        print(\"Nenhum problema encontrado!\")\n",
    "    \n",
    "    return problems\n",
    "\n",
    "# EXECUTAR PARA TODOS OS DATASETS\n",
    "print(\"ANALISANDO ACCIDENTS...\")\n",
    "problems_accidents = safe_quality_analysis(df_accidents, \"Accidents\")\n",
    "\n",
    "print(\"\\nANALISANDO VEHICLES...\")\n",
    "problems_vehicles = safe_quality_analysis(df_vehicles, \"Vehicles\")\n",
    "\n",
    "print(\"\\nANALISANDO CASUALTIES...\") \n",
    "problems_casualties = safe_quality_analysis(df_casualties, \"Casualties\")\n",
    "\n",
    "print(\"\\nAN√ÅLISE DE QUALIDADE CONCLU√çDA PARA TODOS OS DATASETS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96392217",
   "metadata": {},
   "source": [
    "### Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa2bde3-2c4c-470e-b854-dad4554b6ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: String ‚Üí DateType\n",
      "Time: Timestamp ‚Üí String (HH:mm)\n"
     ]
    }
   ],
   "source": [
    "def convert_data_types_simple(df):   \n",
    "    df_converted = df\n",
    "    \n",
    "    # 1. CONVERTER DATE\n",
    "    if 'Date' in df.columns:\n",
    "        df_converted = df_converted.withColumn(\n",
    "            \"Date\", \n",
    "            F.to_date(F.col(\"Date\"), \"dd/MM/yyyy\")\n",
    "        )\n",
    "        print(\"Date: String ‚Üí DateType\")\n",
    "    \n",
    "    # 2. CONVERTER TIME (Timestamp ‚Üí String no formato HH:mm)\n",
    "    if 'Time' in df.columns:\n",
    "        df_converted = df_converted.withColumn(\n",
    "            \"Time\",\n",
    "            F.date_format(F.col(\"Time\"), \"HH:mm\")\n",
    "        )\n",
    "        print(\"Time: Timestamp ‚Üí String (HH:mm)\")\n",
    "        \n",
    "    return df_converted\n",
    "\n",
    "df_accidents_converted = convert_data_types_simple(df_accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cab74",
   "metadata": {},
   "source": [
    "### Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1695037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removidas 289 linhas (0.0162%) com missing em colunas cr√≠ticas\n",
      "Antes: 1,780,653 linhas\n",
      "Depois: 1,780,364 linhas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Depois: 1,780,364 linhas\n",
      "\n",
      "‚úÖ TRATAMENTO DE MISSING CONCLU√çDO!\n"
     ]
    }
   ],
   "source": [
    "def treat_missing_values(df):    \n",
    "    original_count = df.count()\n",
    "    \n",
    "    # COLUNAS CR√çTICAS (se tiver missing, remove a linha)\n",
    "    critical_columns = ['Longitude', 'Latitude', 'Time']\n",
    "    \n",
    "    # Aplicar filtro para remover missing nas colunas cr√≠ticas\n",
    "    condition = None\n",
    "    for col_name in critical_columns:\n",
    "        if col_name in df.columns:\n",
    "            if condition is None:\n",
    "                condition = F.col(col_name).isNotNull()\n",
    "            else:\n",
    "                condition = condition & F.col(col_name).isNotNull()\n",
    "    \n",
    "    if condition is not None:\n",
    "        df_clean = df.filter(condition)\n",
    "        removed_count = original_count - df_clean.count()\n",
    "        removed_pct = (removed_count / original_count) * 100\n",
    "        \n",
    "        print(f\"Removidas {removed_count:,} linhas ({removed_pct:.4f}%) com missing em colunas cr√≠ticas\")\n",
    "        print(f\"Antes: {original_count:,} linhas\")\n",
    "        print(f\"Depois: {df_clean.count():,} linhas\")\n",
    "    else:\n",
    "        df_clean = df\n",
    "        print(\"Nenhum missing encontrado nas colunas cr√≠ticas\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# EXECUTAR TRATAMENTO\n",
    "df_accidents_clean = treat_missing_values(df_accidents_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa45e9",
   "metadata": {},
   "source": [
    "### Referential Integrity Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb7a1db-25ee-48ef-8c2d-4805189ffbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVENDO DADOS √ìRF√ÉOS...\n",
      "Sincronizando datasets...\n",
      "Ve√≠culos: 3,262,270 ‚Üí 3,261,764 (removidos 506)\n",
      "V√≠timas: 2,402,909 ‚Üí 2,402,551 (removidos 358)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ve√≠culos: 3,262,270 ‚Üí 3,261,764 (removidos 506)\n",
      "‚úÖ V√≠timas: 2,402,909 ‚Üí 2,402,551 (removidos 358)\n",
      "\n",
      "‚úÖ INTEGRIDADE REFERENCIAL GARANTIDA!\n"
     ]
    }
   ],
   "source": [
    "def ensure_referential_integrity(accidents_df, vehicles_df, casualties_df):\n",
    "    \"\"\"Remove ve√≠culos e v√≠timas de acidentes exclu√≠dos\"\"\"\n",
    "    print(\"Sincronizando datasets...\")\n",
    "    \n",
    "    # Lista de Accident_Index v√°lidos (ap√≥s limpeza)\n",
    "    valid_accidents = accidents_df.select(\"Accident_Index\").distinct()\n",
    "    \n",
    "    # Contagens antes\n",
    "    vehicles_before = vehicles_df.count()\n",
    "    casualties_before = casualties_df.count()\n",
    "    \n",
    "    # Filtrar ve√≠culos e v√≠timas para manter s√≥ os que t√™m acidentes v√°lidos\n",
    "    vehicles_clean = vehicles_df.join(valid_accidents, \"Accident_Index\", \"inner\")\n",
    "    casualties_clean = casualties_df.join(valid_accidents, \"Accident_Index\", \"inner\")\n",
    "    \n",
    "    # Contagens depois\n",
    "    vehicles_after = vehicles_clean.count()\n",
    "    casualties_after = casualties_clean.count()\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    vehicles_removed = vehicles_before - vehicles_after\n",
    "    casualties_removed = casualties_before - casualties_after\n",
    "    \n",
    "    print(f\"Ve√≠culos: {vehicles_before:,} ‚Üí {vehicles_after:,} (removidos {vehicles_removed:,})\")\n",
    "    print(f\"V√≠timas: {casualties_before:,} ‚Üí {casualties_after:,} (removidos {casualties_removed:,})\")\n",
    "    \n",
    "    return vehicles_clean, casualties_clean\n",
    "\n",
    "# EXECUTAR LIMPEZA DE INTEGRIDADE\n",
    "print(\"REMOVENDO DADOS √ìRF√ÉOS...\")\n",
    "df_vehicles_clean, df_casualties_clean = ensure_referential_integrity(\n",
    "    df_accidents_clean, df_vehicles, df_casualties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f83df",
   "metadata": {},
   "source": [
    "### Domain Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a50440e7-5864-4b00-ad59-3c41613490b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDANDO ACCIDENTS...\n",
      "\n",
      " Accidents - COMPREHENSIVE DOMAIN VALIDATION\n",
      "==================================================\n",
      "   Accident_Severity: Todos os 3 valores est√£o no dom√≠nio\n",
      "   Day_of_Week: Todos os 7 valores est√£o no dom√≠nio\n",
      "   Road_Type: Todos os 6 valores est√£o no dom√≠nio\n",
      "   Speed_limit: Todos os 9 valores est√£o no dom√≠nio\n",
      "   Junction_Detail: Todos os 10 valores est√£o no dom√≠nio\n",
      "   Junction_Control: Todos os 6 valores est√£o no dom√≠nio\n",
      "   Pedestrian_Crossing-Physical_Facilities: Todos os 7 valores est√£o no dom√≠nio\n",
      "   Light_Conditions: Todos os 5 valores est√£o no dom√≠nio\n",
      "   Weather_Conditions: Todos os 10 valores est√£o no dom√≠nio\n",
      "   Road_Surface_Conditions: Todos os 6 valores est√£o no dom√≠nio\n",
      "   Special_Conditions_at_Site: Todos os 9 valores est√£o no dom√≠nio\n",
      "   Carriageway_Hazards: Todos os 7 valores est√£o no dom√≠nio\n",
      "   Urban_or_Rural_Area: Todos os 3 valores est√£o no dom√≠nio\n",
      "\n",
      "RESUMO DE VALIDA√á√ÉO:\n",
      "------------------------------\n",
      "Todos os dom√≠nios est√£o v√°lidos!\n",
      "\n",
      "VALIDANDO VEHICLES...\n",
      "\n",
      " Vehicles - COMPREHENSIVE DOMAIN VALIDATION\n",
      "==================================================\n",
      "   Vehicle_Type: Todos os 21 valores est√£o no dom√≠nio\n",
      "   Vehicle_Manoeuvre: Todos os 19 valores est√£o no dom√≠nio\n",
      "   Vehicle_Location-Restricted_Lane: Todos os 11 valores est√£o no dom√≠nio\n",
      "   Sex_of_Driver: Todos os 4 valores est√£o no dom√≠nio\n",
      "   Age_Band_of_Driver: Todos os 12 valores est√£o no dom√≠nio\n",
      "   Propulsion_Code: Todos os 13 valores est√£o no dom√≠nio\n",
      "\n",
      "RESUMO DE VALIDA√á√ÉO:\n",
      "------------------------------\n",
      "Todos os dom√≠nios est√£o v√°lidos!\n",
      "\n",
      "VALIDANDO CASUALTIES...\n",
      "\n",
      " Casualties - COMPREHENSIVE DOMAIN VALIDATION\n",
      "==================================================\n",
      "   Casualty_Class: Todos os 3 valores est√£o no dom√≠nio\n",
      "   Sex_of_Casualty: Todos os 3 valores est√£o no dom√≠nio\n",
      "   Age_Band_of_Casualty: Todos os 12 valores est√£o no dom√≠nio\n",
      "   Casualty_Severity: Todos os 3 valores est√£o no dom√≠nio\n",
      "   Pedestrian_Movement: Todos os 11 valores est√£o no dom√≠nio\n",
      "   Car_Passenger: Todos os 4 valores est√£o no dom√≠nio\n",
      "   Bus_or_Coach_Passenger: Todos os 6 valores est√£o no dom√≠nio\n",
      "   Casualty_Type: Todos os 21 valores est√£o no dom√≠nio\n",
      "\n",
      "RESUMO DE VALIDA√á√ÉO:\n",
      "------------------------------\n",
      "Todos os dom√≠nios est√£o v√°lidos!\n",
      "\n",
      " VALIDA√á√ÉO COMPLETA DE DOM√çNIOS CONCLU√çDA!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Accident_Severity: Todos os 3 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Day_of_Week: Todos os 7 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Road_Type: Todos os 6 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Speed_limit: Todos os 9 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Junction_Detail: Todos os 10 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Junction_Control: Todos os 6 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Pedestrian_Crossing-Physical_Facilities: Todos os 7 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Light_Conditions: Todos os 5 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Weather_Conditions: Todos os 10 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Road_Surface_Conditions: Todos os 6 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Special_Conditions_at_Site: Todos os 9 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Carriageway_Hazards: Todos os 7 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Urban_or_Rural_Area: Todos os 3 valores est√£o no dom√≠nio\n",
      "\n",
      "üìä RESUMO DE VALIDA√á√ÉO:\n",
      "------------------------------\n",
      "Todos os dom√≠nios est√£o v√°lidos!\n",
      "\n",
      "VALIDANDO VEHICLES...\n",
      "\n",
      " Vehicles - COMPREHENSIVE DOMAIN VALIDATION\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Vehicle_Type: Todos os 21 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Vehicle_Manoeuvre: Todos os 19 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Vehicle_Location-Restricted_Lane: Todos os 11 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Sex_of_Driver: Todos os 4 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Age_Band_of_Driver: Todos os 12 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Propulsion_Code: Todos os 13 valores est√£o no dom√≠nio\n",
      "\n",
      "üìä RESUMO DE VALIDA√á√ÉO:\n",
      "------------------------------\n",
      "Todos os dom√≠nios est√£o v√°lidos!\n",
      "\n",
      "VALIDANDO CASUALTIES...\n",
      "\n",
      " Casualties - COMPREHENSIVE DOMAIN VALIDATION\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Casualty_Class: Todos os 3 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Sex_of_Casualty: Todos os 3 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Age_Band_of_Casualty: Todos os 12 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Casualty_Severity: Todos os 3 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Pedestrian_Movement: Todos os 11 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Car_Passenger: Todos os 4 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Bus_or_Coach_Passenger: Todos os 6 valores est√£o no dom√≠nio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Casualty_Type: Todos os 21 valores est√£o no dom√≠nio\n",
      "\n",
      "üìä RESUMO DE VALIDA√á√ÉO:\n",
      "------------------------------\n",
      "Todos os dom√≠nios est√£o v√°lidos!\n",
      "\n",
      " VALIDA√á√ÉO COMPLETA DE DOM√çNIOS CONCLU√çDA!\n"
     ]
    }
   ],
   "source": [
    "def validate_all_domains(df, df_name):\n",
    "    \"\"\"Valida TODAS as colunas com c√≥digos\"\"\"\n",
    "    print(f\"\\n {df_name} - COMPREHENSIVE DOMAIN VALIDATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    validation_rules = {\n",
    "        # ACCIDENTS\n",
    "        'Accident_Severity': [1, 2, 3],\n",
    "        'Day_of_Week': [1, 2, 3, 4, 5, 6, 7],\n",
    "        'Road_Type': [1, 2, 3, 6, 7, 9, 12],\n",
    "        'Speed_limit': [0, 10, 15, 20, 30, 40, 50, 60, 70],\n",
    "        'Junction_Detail': [0, 1, 2, 3, 5, 6, 7, 8, 9, -1],\n",
    "        'Junction_Control': [0, 1, 2, 3, 4, -1],\n",
    "        'Pedestrian_Crossing-Physical_Facilities': [0, 1, 4, 5, 7, 8, -1],\n",
    "        'Light_Conditions': [1, 4, 5, 6, 7, -1],\n",
    "        'Weather_Conditions': [1, 2, 3, 4, 5, 6, 7, 8, 9, -1],\n",
    "        'Road_Surface_Conditions': [1, 2, 3, 4, 5, 6, 7, -1],\n",
    "        'Special_Conditions_at_Site': [0, 1, 2, 3, 4, 5, 6, 7, -1],\n",
    "        'Carriageway_Hazards': [0, 1, 2, 3, 4, 5, 6, 7, -1],\n",
    "        'Urban_or_Rural_Area': [1, 2, 3],\n",
    "        \n",
    "        # VEHICLES\n",
    "        'Vehicle_Type': list(range(1, 99)) + [-1],  # 1-98 + -1\n",
    "        'Vehicle_Manoeuvre': list(range(1, 19)) + [-1],\n",
    "        'Vehicle_Location-Restricted_Lane': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, -1],\n",
    "        'Sex_of_Driver': [1, 2, 3, -1],\n",
    "        'Age_Band_of_Driver': list(range(1, 12)) + [-1],\n",
    "        'Propulsion_Code': list(range(1, 13)) + [-1],\n",
    "        \n",
    "        # CASUALTIES  \n",
    "        'Casualty_Class': [1, 2, 3],\n",
    "        'Sex_of_Casualty': [1, 2, 3, -1],\n",
    "        'Age_Band_of_Casualty': list(range(1, 12)) + [-1],\n",
    "        'Casualty_Severity': [1, 2, 3],\n",
    "        'Pedestrian_Movement': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, -1],\n",
    "        'Car_Passenger': [0, 1, 2, 9, -1],\n",
    "        'Bus_or_Coach_Passenger': [0, 1, 2, 3, 4, 9, -1],\n",
    "        'Casualty_Type': [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 90, 97, 98, -1]\n",
    "    }\n",
    "    \n",
    "    for col_name, valid_values in validation_rules.items():\n",
    "        if col_name in df.columns:\n",
    "            # Contar valores fora do dom√≠nio\n",
    "            invalid_count = df.filter(~F.col(col_name).isin(valid_values)).count()\n",
    "            \n",
    "            if invalid_count > 0:\n",
    "                # Pegar exemplos dos valores inv√°lidos\n",
    "                invalid_samples = df.filter(~F.col(col_name).isin(valid_values)) \\\n",
    "                                  .select(col_name).distinct().limit(3).collect()\n",
    "                \n",
    "                samples = [row[col_name] for row in invalid_samples]\n",
    "                issues.append(f\"{col_name}: {invalid_count} inv√°lidos - Ex: {samples}\")\n",
    "                print(f\"   {col_name}: {invalid_count} valores inv√°lidos\")\n",
    "                print(f\"      Exemplos: {samples}\")\n",
    "            else:\n",
    "                print(f\"   {col_name}: Todos os {df.select(col_name).distinct().count()} valores est√£o no dom√≠nio\")\n",
    "    \n",
    "    print(f\"\\nRESUMO DE VALIDA√á√ÉO:\")\n",
    "    print(\"-\" * 30)\n",
    "    if issues:\n",
    "        print(f\"‚ö†  Problemas encontrados: {len(issues)}\")\n",
    "        for issue in issues:\n",
    "            print(f\"   ‚Ä¢ {issue}\")\n",
    "    else:\n",
    "        print(\"Todos os dom√≠nios est√£o v√°lidos!\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# EXECUTAR VALIDA√á√ÉO COMPLETA\n",
    "print(\"VALIDANDO ACCIDENTS...\")\n",
    "issues_accidents = validate_all_domains(df_accidents_clean, \"Accidents\")\n",
    "\n",
    "print(\"\\nVALIDANDO VEHICLES...\")\n",
    "issues_vehicles = validate_all_domains(df_vehicles_clean, \"Vehicles\")\n",
    "\n",
    "print(\"\\nVALIDANDO CASUALTIES...\")\n",
    "issues_casualties = validate_all_domains(df_casualties_clean, \"Casualties\")\n",
    "\n",
    "print(\"\\n VALIDA√á√ÉO COMPLETA DE DOM√çNIOS CONCLU√çDA!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b991aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas para snake_case\n",
    "def rename_columns(df, rename_dict):\n",
    "    df_renamed = df\n",
    "    for col_name in df.columns:\n",
    "        df_renamed = df_renamed.withColumnRenamed(col_name, col_name.lower())\n",
    "\n",
    "    for old_name, new_name in rename_dict.items():\n",
    "        if old_name in df_renamed.columns:\n",
    "            df_renamed = df_renamed.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "    return df_renamed\n",
    "\n",
    "renomear = {\"date\": \"accident_timestamp\", \"time\": \"accident_time\", \"pedestrian_crossing-physical_facilities\": \"pedestrian_crossing_physical_facilities\", \"was_vehicle_left_hand_drive?\": \"was_vehicle_left_hand_drive\", \"vehicle_location-restricted_lane\": \"vehicle_location_restricted_lane\"}\n",
    "df_accidents_clean = rename_columns(df_accidents_clean, renomear)\n",
    "df_vehicles_clean = rename_columns(df_vehicles_clean, renomear)\n",
    "df_casualties_clean = rename_columns(df_casualties_clean, renomear)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c40c6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe final: 2,402,551 linhas, 40 colunas\n",
      "root\n",
      " |-- accident_index: string (nullable = true)\n",
      " |-- vehicle_reference: integer (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- accident_severity: integer (nullable = true)\n",
      " |-- number_of_vehicles: integer (nullable = true)\n",
      " |-- number_of_casualties: integer (nullable = true)\n",
      " |-- accident_timestamp: date (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- accident_time: string (nullable = true)\n",
      " |-- road_type: integer (nullable = true)\n",
      " |-- speed_limit: integer (nullable = true)\n",
      " |-- junction_detail: integer (nullable = true)\n",
      " |-- junction_control: integer (nullable = true)\n",
      " |-- pedestrian_crossing_physical_facilities: integer (nullable = true)\n",
      " |-- light_conditions: integer (nullable = true)\n",
      " |-- weather_conditions: integer (nullable = true)\n",
      " |-- road_surface_conditions: integer (nullable = true)\n",
      " |-- special_conditions_at_site: integer (nullable = true)\n",
      " |-- carriageway_hazards: integer (nullable = true)\n",
      " |-- urban_or_rural_area: integer (nullable = true)\n",
      " |-- vehicle_type: integer (nullable = true)\n",
      " |-- vehicle_manoeuvre: integer (nullable = true)\n",
      " |-- vehicle_location_restricted_lane: integer (nullable = true)\n",
      " |-- was_vehicle_left_hand_drive: integer (nullable = true)\n",
      " |-- sex_of_driver: integer (nullable = true)\n",
      " |-- age_of_driver: integer (nullable = true)\n",
      " |-- age_band_of_driver: integer (nullable = true)\n",
      " |-- propulsion_code: integer (nullable = true)\n",
      " |-- age_of_vehicle: integer (nullable = true)\n",
      " |-- casualty_reference: integer (nullable = true)\n",
      " |-- casualty_class: integer (nullable = true)\n",
      " |-- sex_of_casualty: integer (nullable = true)\n",
      " |-- age_of_casualty: integer (nullable = true)\n",
      " |-- age_band_of_casualty: integer (nullable = true)\n",
      " |-- casualty_severity: integer (nullable = true)\n",
      " |-- pedestrian_movement: integer (nullable = true)\n",
      " |-- car_passenger: integer (nullable = true)\n",
      " |-- bus_or_coach_passenger: integer (nullable = true)\n",
      " |-- casualty_type: integer (nullable = true)\n",
      "\n",
      "--- Dataframe 'df_joined' persistido na mem√≥ria ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Defina o plano de Join (continua 'lazy')\n",
    "df_joined_base = df_accidents_clean \\\n",
    "    .join(df_vehicles_clean, on=\"accident_index\", how=\"inner\") \\\n",
    "    .join(df_casualties_clean, on=[\"accident_index\", \"vehicle_reference\"], how=\"inner\")\n",
    "\n",
    "# 2. D√™ a ordem para PERSISTIR o resultado na mem√≥ria (e disco)\n",
    "df_joined = df_joined_base.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# 3. Chame a A√á√ÉO (.count())\n",
    "# AGORA o Spark vai:\n",
    "#   a) Executar o join UMA VEZ.\n",
    "#   b) Salvar o resultado (df_joined) na mem√≥ria.\n",
    "#   c) Te dar a contagem.\n",
    "print(f\"Dataframe final: {df_joined.count():,} linhas, {len(df_joined.columns)} colunas\")\n",
    "\n",
    "# 4. Mostre o Schema\n",
    "df_joined.printSchema()\n",
    "\n",
    "print(\"--- Dataframe 'df_joined' persistido na mem√≥ria ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edbfb96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Todos os dataframes foram salvos em Parquet!\n"
     ]
    }
   ],
   "source": [
    "df_accidents_clean.write.mode(\"overwrite\").parquet(os.path.join(FILE_TABELAS_DIR, \"accident\"))\n",
    "df_vehicles_clean.write.mode(\"overwrite\").parquet(os.path.join(FILE_TABELAS_DIR, \"vehicle\"))\n",
    "df_casualties_clean.write.mode(\"overwrite\").parquet(os.path.join(FILE_TABELAS_DIR, \"casualty\"))\n",
    "df_joined.write.mode(\"overwrite\").parquet(os.path.join(FILE_TABELAS_DIR, \"joined\"))\n",
    "\n",
    "print(\"‚úÖ Todos os dataframes foram salvos em Parquet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b9d29a",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1411.jdbc.\n: java.lang.ClassNotFoundException: org.postgresql.Driver\r\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:47)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:112)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:112)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:112)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:272)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:276)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:79)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:77)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:88)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:155)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:155)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\r\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:154)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:164)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:470)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:470)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:446)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:164)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:126)\r\n\tat scala.util.Try$.apply(Try.scala:217)\r\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\r\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\r\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:334)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\r\n\t\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\r\n\t\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)\r\n\t\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:47)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:112)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:112)\r\n\t\tat scala.Option.foreach(Option.scala:437)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:112)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:272)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:276)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\r\n\t\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\r\n\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:79)\r\n\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:77)\r\n\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:88)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:155)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\r\n\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\t\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\t\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\r\n\t\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\r\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:155)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:154)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:169)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:164)\r\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:470)\r\n\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:470)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:446)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:164)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:126)\r\n\t\tat scala.util.Try$.apply(Try.scala:217)\r\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\r\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\r\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\r\n\t\t... 20 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_renamed\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Salvar os dataframes no Postgres\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mdf_joined\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moverwrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpostgres_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjoined\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpostgres_properties\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m df_casualties_clean.write.mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m).jdbc(\n\u001b[32m     23\u001b[39m     url=postgres_url,\n\u001b[32m     24\u001b[39m     table=\u001b[33m\"\u001b[39m\u001b[33mcasualty\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     properties=postgres_properties\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m df_vehicles_clean.write.mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m).jdbc(\n\u001b[32m     29\u001b[39m     url=postgres_url,\n\u001b[32m     30\u001b[39m     table=\u001b[33m\"\u001b[39m\u001b[33mvehicle\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m     properties=postgres_properties\n\u001b[32m     32\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pyspark\\sql\\readwriter.py:2347\u001b[39m, in \u001b[36mDataFrameWriter.jdbc\u001b[39m\u001b[34m(self, url, table, mode, properties)\u001b[39m\n\u001b[32m   2345\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[32m   2346\u001b[39m     jprop.setProperty(k, properties[k])\n\u001b[32m-> \u001b[39m\u001b[32m2347\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjprop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o1411.jdbc.\n: java.lang.ClassNotFoundException: org.postgresql.Driver\r\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:47)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:112)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:112)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:112)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:272)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:276)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:79)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:77)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:88)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:155)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:155)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\r\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:154)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:169)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:164)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:470)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:470)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:446)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:164)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:126)\r\n\tat scala.util.Try$.apply(Try.scala:217)\r\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\r\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\r\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:334)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\r\n\t\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\r\n\t\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)\r\n\t\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:47)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:112)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:112)\r\n\t\tat scala.Option.foreach(Option.scala:437)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:112)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:272)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:276)\r\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\r\n\t\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:55)\r\n\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:79)\r\n\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:77)\r\n\t\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:88)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:155)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\r\n\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\t\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\t\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\r\n\t\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\r\n\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:155)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:154)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:169)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:164)\r\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:470)\r\n\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:470)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)\r\n\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:446)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:164)\r\n\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:126)\r\n\t\tat scala.util.Try$.apply(Try.scala:217)\r\n\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\r\n\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\r\n\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\r\n\t\t... 20 more\r\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes do banco de dados Postgres\n",
    "postgres_url = \"jdbc:postgresql://db:5432/gis\"\n",
    "postgres_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "def lowercase_columns(df):\n",
    "    df_renamed = df\n",
    "    for col_name in df.columns:\n",
    "        df_renamed = df_renamed.withColumnRenamed(col_name, col_name.lower())\n",
    "    return df_renamed\n",
    "\n",
    "# Salvar os dataframes no Postgres\n",
    "df_joined.write.mode(\"overwrite\").jdbc(\n",
    "    url=postgres_url,\n",
    "    table=\"joined\",\n",
    "    properties=postgres_properties\n",
    ")\n",
    "\n",
    "df_casualties_clean.write.mode(\"overwrite\").jdbc(\n",
    "    url=postgres_url,\n",
    "    table=\"casualty\",\n",
    "    properties=postgres_properties\n",
    ")\n",
    "\n",
    "df_vehicles_clean.write.mode(\"overwrite\").jdbc(\n",
    "    url=postgres_url,\n",
    "    table=\"vehicle\",\n",
    "    properties=postgres_properties\n",
    ")\n",
    "\n",
    "\n",
    "df_accidents_clean.write.mode(\"overwrite\").jdbc(\n",
    "    url=postgres_url,\n",
    "    table=\"accident\",\n",
    "    properties=postgres_properties\n",
    ")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Todos os dataframes foram salvos no banco de dados Postgres!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb332d",
   "metadata": {},
   "source": [
    "### Grafico Quantidade de Acidentes por severidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693213b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_severity = df_accidents_clean.groupBy(\"Accident_Severity\").count().orderBy(\"Accident_Severity\").toPandas()\n",
    "\n",
    "severity_map = {1: 'Fatal', 2: 'S√©rio', 3: 'Leve'}\n",
    "accident_severity['Severity_Label'] = accident_severity['Accident_Severity'].map(severity_map)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(accident_severity['Severity_Label'], accident_severity['count'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:,.0f}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel(\"Severidade do Acidente\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.title(\"Distribui√ß√£o de Acidentes por Severidade\")\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x/1e6:.1f}M'))\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28512eb3",
   "metadata": {},
   "source": [
    "### Acidentes por dia da semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_data = df_joined.groupBy(\"day_of_week\").count().orderBy(\"day_of_week\").toPandas()\n",
    "days_map = {1: 'Domingo', 2: 'Segunda', 3: 'Ter√ßa', 4: 'Quarta', 5: 'Quinta', 6: 'Sexta', 7: 'S√°bado'}\n",
    "day_data['day_name'] = day_data['day_of_week'].map(days_map)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(day_data['day_name'], day_data['count'], color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Dia da Semana')\n",
    "plt.ylabel('N√∫mero de Acidentes')\n",
    "plt.title('Acidentes por Dia da Semana')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa62ab",
   "metadata": {},
   "source": [
    "### Severidade dos acidentes por condi√ß√µes climaticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d75383",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = df_joined.groupBy(\"weather_conditions\", \"accident_severity\").count().toPandas()\n",
    "pivot_weather = weather_data.pivot(index='weather_conditions', columns='accident_severity', values='count').fillna(0)\n",
    "weather_map = {-1:'Sem dados de clima' ,1: 'Bom tempo', 2: 'Chuva sem vento', 3: 'Neve sem vento', 4: 'Ventania', 5:'Chovendo com ventos', 6: 'Neve com ventos', 7: 'Neblina', 8: 'Outros', 9: 'Desconhecido'}\n",
    "pivot_weather.index = pivot_weather.index.map(weather_map)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pivot_weather.plot(kind='bar', stacked=True, color=['red', 'orange', 'green'])\n",
    "plt.xlabel('Condi√ß√µes Clim√°ticas')\n",
    "plt.ylabel('N√∫mero de Acidentes')\n",
    "plt.title('Severidade dos Acidentes por Condi√ß√µes Clim√°ticas')\n",
    "plt.legend(['Fatal', 'S√©rio', 'Leve'], title='Severidade')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99eb98",
   "metadata": {},
   "source": [
    "### Urbano X Rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_rural_data = df_joined.groupBy(\"urban_or_rural_area\", \"accident_severity\").count().toPandas()\n",
    "area_map = {1: 'Urbana', 2: 'Rural'}\n",
    "severity_map = {1: 'Fatal', 2: 'S√©rio', 3: 'Leve'}\n",
    "urban_rural_data['area_label'] = urban_rural_data['urban_or_rural_area'].map(area_map)\n",
    "urban_rural_data['severity_label'] = urban_rural_data['accident_severity'].map(severity_map)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=urban_rural_data, x='area_label', y='count', hue='severity_label', palette='RdYlGn_r')\n",
    "plt.xlabel('Tipo de √Årea')\n",
    "plt.ylabel('N√∫mero de Acidentes')\n",
    "plt.title('Compara√ß√£o de Severidade: √Årea Urbana vs Rural')\n",
    "plt.legend(title='Severidade')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea6bec",
   "metadata": {},
   "source": [
    "### Tendencia de acidentes por idade do veiculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_age_data = df_joined.select(\n",
    "    F.col(\"age_of_vehicle\").cast(\"int\").alias(\"vehicle_age\"),\n",
    "    F.col(\"accident_index\")\n",
    ").filter(F.col(\"age_of_vehicle\").isNotNull() & \n",
    "         (F.col(\"age_of_vehicle\") >= 0) & \n",
    "         (F.col(\"age_of_vehicle\") <= 20))\n",
    "\n",
    "exact_age_count = exact_age_data.groupBy(\"vehicle_age\").count().orderBy(\"vehicle_age\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(exact_age_count['vehicle_age'], exact_age_count['count'], marker='o', linewidth=2, markersize=4)\n",
    "plt.xlabel('Idade do Ve√≠culo (anos)')\n",
    "plt.ylabel('N√∫mero de Acidentes')\n",
    "plt.title('Rela√ß√£o entre Idade do Ve√≠culo e N√∫mero de Acidentes')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "max_age = exact_age_count.loc[exact_age_count['count'].idxmax()]\n",
    "plt.annotate(f'Pico: {max_age[\"count\"]:,} acidentes\\naos {max_age[\"vehicle_age\"]} anos', \n",
    "             xy=(max_age['vehicle_age'], max_age['count']),\n",
    "             xytext=(10, 30), textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7940d9",
   "metadata": {},
   "source": [
    "Distribui√ß√£o de V√≠timas por Idade e G√™nero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid_data = df_joined.select(\n",
    "    F.col(\"age_of_casualty\").cast(\"int\").alias(\"age\"),\n",
    "    F.col(\"sex_of_casualty\").alias(\"gender\")\n",
    ").filter(\n",
    "    (F.col(\"age\").isNotNull()) & \n",
    "    (F.col(\"age\") > 0) & \n",
    "    (F.col(\"age\") <= 90) &\n",
    "    (F.col(\"gender\").isin([1, 2]))\n",
    ")\n",
    "\n",
    "age_bins = [\n",
    "    (0, 10, \"0-10\"),\n",
    "    (11, 20, \"11-20\"), \n",
    "    (21, 30, \"21-30\"),\n",
    "    (31, 40, \"31-40\"),\n",
    "    (41, 50, \"41-50\"),\n",
    "    (51, 60, \"51-60\"),\n",
    "    (61, 70, \"61-70\"),\n",
    "    (71, 80, \"71-80\"),\n",
    "    (81, 90, \"81-90\")\n",
    "]\n",
    "\n",
    "condition_expr = F.when((F.col(\"age\") >= 0) & (F.col(\"age\") <= 10), \"0-10\")\n",
    "for min_age, max_age, label in age_bins[1:]:\n",
    "    condition_expr = condition_expr.when((F.col(\"age\") >= min_age) & (F.col(\"age\") <= max_age), label)\n",
    "\n",
    "pyramid_data = pyramid_data.withColumn(\"age_group\", condition_expr)\n",
    "\n",
    "pyramid_counts = pyramid_data.groupBy(\"age_group\", \"gender\").count().orderBy(\"age_group\").collect()\n",
    "\n",
    "age_labels = [label for _, _, label in age_bins]\n",
    "male_counts = [0] * len(age_labels)\n",
    "female_counts = [0] * len(age_labels)\n",
    "\n",
    "for row in pyramid_counts:\n",
    "    age_group = row['age_group']\n",
    "    gender = row['gender']\n",
    "    count = row['count']\n",
    "    \n",
    "    idx = age_labels.index(age_group)\n",
    "    if gender == 1:  # Masculino\n",
    "        male_counts[idx] = count\n",
    "    elif gender == 2:  # Feminino\n",
    "        female_counts[idx] = count\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "y_pos = np.arange(len(age_labels))\n",
    "ax.barh(y_pos, [-x for x in male_counts], color='blue', alpha=0.7, label='Masculino')\n",
    "ax.barh(y_pos, female_counts, color='pink', alpha=0.7, label='Feminino')\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(age_labels)\n",
    "ax.set_xlabel('N√∫mero de V√≠timas')\n",
    "ax.set_ylabel('Faixa Et√°ria')\n",
    "ax.set_title('Pir√¢mide Et√°ria das V√≠timas de Acidentes\\nDistribui√ß√£o por Idade e G√™nero')\n",
    "\n",
    "for i, (male, female) in enumerate(zip(male_counts, female_counts)):\n",
    "    if male > 0:\n",
    "        ax.text(-male-50, i, f'{male:,}', ha='right', va='center', fontsize=9, color='white')\n",
    "    if female > 0:\n",
    "        ax.text(female+50, i, f'{female:,}', ha='left', va='center', fontsize=9, color='black')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
